{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://miro.medium.com/max/854/0*bfgOZEZqaXYB2yRo.jpg\" style = \"height:300px;width:100%;\">\n",
    "<h1 style = \"float:center;\">A Credit Scoring Model</h1>\n",
    "<p> The Credit score willbe a probability attached to each new customer on their ability to pay a loan based on data from past loans. Those with low probabilities will either receive no loans or just receive very low loan until their ability to pay is analised via experience</p> \n",
    "<p> The data comes from the popular peer to peer lending website:  <a href = \"https://www.lendingclub.com/info/download-data.action\">Lending Club</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Exploration and Cleaning</h2>\n",
    "<h3>Cleaning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Necessary Libraries\n",
    "import os\n",
    "os.listdir('.ipynb_checkpoints')\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Print all rows and columns. Dont hide any\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'LoanStats3a.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6f84591ce123>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mloans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LoanStats3a.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'LoanStats3a.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "%time\n",
    "loans = pd.read_csv('LoanStats3a.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(loans.columns)\n",
    "print(loans.shape)\n",
    "#loans.isnull().sum()\n",
    "loans = loans.dropna(axis='columns', how='all')\n",
    "loans = loans.dropna(axis=0, how='all')\n",
    "print(loans.shape)\n",
    "\n",
    "thresh = len(loans) * .6\n",
    "loans.dropna(thresh = thresh, axis = 1, inplace = True)\n",
    "# Checking for missing values in filtered data frame\n",
    "loans.apply(lambda x: sum(x.isnull()),axis=0) \n",
    "print(loans.shape)\n",
    "loans.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loans.isnull().sum()\n",
    "loans = loans[(loans['loan_status']=='Fully Paid') | (loans['loan_status']=='Charged Off')]\n",
    "loans['loan_status_bin'] = loans['loan_status'].map({'Charged Off': 1, 'Fully Paid': 0}) # 0 good loans 1 bad loans\n",
    "loans.loan_status_bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variables used for the analysis\n",
    "loans.columns\n",
    "columns  = ['loan_amnt',      # The Amount of Loan Requested\n",
    "            'loan_status_bin',# A Binary loan status with 1 being bad loans and 0 being Good loans\n",
    "            'funded_amnt',    #The amount that was Given\n",
    "            'term',           # 3 or five year loan\n",
    "            'int_rate',       # the interest rate charged\n",
    "            'installment',    # The intallment amount paid\n",
    "            'emp_length',     #How long the person has bein under employment\n",
    "            'home_ownership', #What ownership they have for their home, rental owned or mortgage\n",
    "            'annual_inc',     # annual income\n",
    "            'verification_status',# was the income source verified\n",
    "           'loan_status',     # is the loan paid fully or defaulted\n",
    "            'purpose',        # The purpose for taking the loan\n",
    "           ]\n",
    "print(len(columns))\n",
    "loans.term.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Null values\n",
    "df = loans[columns]\n",
    "print(df.shape)\n",
    "df.isnull().sum()\n",
    "#df['emp_length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data imputation\n",
    "#df['emp_length'] = df['emp_length'].fillna('10+ years')\n",
    "interest =  [float(i[:6]) for i in df.int_rate] # converts the interest rates to numerical value\n",
    "df.int_rate = interest\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dummies for all categorical variables\n",
    "lis = ['term','emp_length','home_ownership','verification_status','purpose']\n",
    "df[lis[2]] = ['OTHER_Home_Ownership' if (i == 'OTHER' or i == 'NONE') else i for i in df[lis[2]]] # rename 'other'\n",
    "df[lis[4]] = ['OTHER_Purposes' if (i == 'other' ) else i for i in df[lis[4]]]# rename 'other'\n",
    "df['emp_length'] = df['emp_length'].fillna(df['emp_length'].mode()[0])\n",
    "\n",
    "df_clean = pd.DataFrame(index = df.index)\n",
    "for i in lis:\n",
    "    H = df[i]\n",
    "    \n",
    "    H_dum = pd.get_dummies(H)\n",
    "    \n",
    "    B = pd.concat((df_clean,H_dum),1)\n",
    "    df_clean = B\n",
    "    \n",
    "    print(B.shape)\n",
    "df_cleans = pd.concat((df,B),1)\n",
    "df_cleans.isnull().sum()\n",
    "df_cleans[df_cleans.columns.difference(lis + ['loan_status_bin','loan_status'])].info()\n",
    "df_cleans.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(20,20),color = \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def emp_to_num(term):\n",
    "    \"\"\"converts the employment column to numerical values ranging from 0 - 10\"\"\"\n",
    "    if pd.isna(term):\n",
    "        return None\n",
    "    elif term[2]=='+':\n",
    "        return 10\n",
    "    elif term[0]=='<':\n",
    "        return 0\n",
    "    else:\n",
    "        return int(term[0])\n",
    "\n",
    "df['emp_length_num'] = df['emp_length'].apply(emp_to_num)\n",
    "plt.title('Employment in Years')\n",
    "(df['emp_length_num'].value_counts().sort_index()/len(df)).plot.bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is there a connection between the employment and the default rate\n",
    "df.groupby('emp_length_num')['loan_status_bin'].mean().plot.bar()\n",
    "'''Intrestingly there is no obvious connection between employment length and default rate. For example employment lengths of 8 and 9 years have almost the same default rate as employment lengths of up to 1 year. But what we can see is that an employment length of 0 or 1 has a high default rate and an emloyment length of more than 10 years has a really low default rate. So we are going to transform the feature into two features called 'long_emp' and 'short_emp'.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of interest rates\n",
    "#(df['int_rate'].dropna()/len(df)).plot.hist(bins=10)\n",
    "# Purpose for the loans\n",
    "\n",
    "(df['purpose'].value_counts()/len(df)).plot.bar()\n",
    "plt.xticks(rotation= 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The term of loans vis a vis the default rate\n",
    "(df['term'].value_counts()/len(df)).plot.bar(title='value counts') # more short term loans than long term loans\n",
    "df.groupby('term')['loan_status_bin'].mean().plot.bar(title='default rate') # higher default rate in longer loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Those that rent their houses have a high default rate\n",
    "df[(df['home_ownership']=='MORTGAGE') | (df['home_ownership']=='OWN')| (df['home_ownership']=='RENT')].groupby('home_ownership')['loan_status_bin'].mean().plot.bar(title='default rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Machine Learning Model\n",
    "### Create an X and Y  - input output dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the data ti improve overall performance\n",
    "filter1 = df_cleans.loan_status_bin == 0\n",
    "filter2 = df_cleans.loan_status_bin == 1\n",
    "good_loans = df_cleans[filter1]\n",
    "bad_loans = df_cleans[filter2]\n",
    "slices = good_loans.iloc[:5670,:]\n",
    "new = pd.concat((bad_loans,slices),0)\n",
    "print(good_loans.shape,bad_loans.shape,new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries for spliting, testing and training the model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "X = df_cleans[df_cleans.columns.difference(lis + ['loan_status_bin','loan_status'])]\n",
    "Y = df_cleans['loan_status_bin']\n",
    "\n",
    "X1 = new[df_cleans.columns.difference(lis + ['loan_status_bin','loan_status'])]\n",
    "Y1 = new['loan_status_bin']\n",
    "X11 = X1.iloc[:11339, :]\n",
    "X11.to_csv(\"X1.csv\",index = False)\n",
    "Y1.to_csv(\"Y1.csv\", index = False)\n",
    "print(X.shape,Y.shape)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X1,Y1,test_size = 0.2)\n",
    "sc = MinMaxScaler()\n",
    "clf1 = RandomForestClassifier(n_estimators = 100 ,verbose=1,random_state=324) \n",
    "clf = LogisticRegression(penalty='l1', C=0.01,verbose = 1)\n",
    "\n",
    "pipe_lr = Pipeline([('scaler', sc), ('clf1', clf1)])\n",
    "\n",
    "#Train the model\n",
    "pipe_lr.fit(X_train, Y_train)\n",
    "# Save the model to the local machine\n",
    "filename = 'model.pickle'\n",
    "pickle.dump(pipe_lr, open(filename, 'wb'))\n",
    "X1.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report to see how well the model performs\n",
    "preds = pipe_lr.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test,preds))\n",
    "print(confusion_matrix(Y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation _ a visual approach using the (receiver_operating_curve (ROC))\n",
    "test_probas = pipe_lr.predict_proba(X_test)[:,1]\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "ax = plt.figure(figsize = (7,7))\n",
    "fpr, tpr, tresholds = roc_curve(Y_test, test_probas)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], color = 'red')\n",
    "plt.title('ROC')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "\n",
    "print('ROC-AUC-score: ', roc_auc_score(Y_test, test_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using Random Data\n",
    "filter1 = df_cleans.loan_status_bin ==0\n",
    "supers = df_cleans[filter1]\n",
    "row = supers.iloc[0:4,:]\n",
    "row = row[row.columns.difference(lis + ['loan_status_bin','loan_status'])]\n",
    "def credit_score(row):\n",
    "    probability = pipe_lr.predict_proba(row)\n",
    "    df = pd.DataFrame(probability)\n",
    "    print(probability[:,0])\n",
    "    thresh = 10\n",
    "    return probability[:,0]*thresh\n",
    "\n",
    "\n",
    "\n",
    "credit_score(row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Actionable items based on the model</h1>\n",
    "* The model can be used as is on new customers whose data would be uploaded as csv and the output would be a credit score, the compnay would then use a score card to assign loans based on the credit score.\n",
    "* The model can also be used by non datascientists using a dashboard created using ipywidgets or equivalent complete with a graphical user interface (GUI)\n",
    "* The model can be used as the analytical base for a website where users log in and fill in a form, the model would use the data from this form to generate credit score that would be used to give loans. this can be achieved through use of Flask or Django in python or their equivalents in other programing languages. An example of this is vailable on github <a href = \"https://github.com/sophicist/Flask-Apps/tree/master/credit%20scorer\">  here</a>\n",
    "* this model can also be interlinked with an already existing website that would approve loans based on the credit scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ways to improve the models\n",
    "* use the full lendeable dataset\n",
    "* use ensemble machine learning models such as voting to improve performance\n",
    "* use deep neural networks and test performance\n",
    "* use Bayes statistics to improve the model and to make it more Kenyan ( add more questions on the flask form)\n",
    "* convert the dollars to Kenyan currency\n",
    "* add the number of variables from the current 11\n",
    "* link the model to the crb ratings and Mpesa data to get more information on the client\n",
    "* Create a baseline model for the same to see how well the model performs\n",
    "* look for a kenyan dataset and test the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
